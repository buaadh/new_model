Number of runs: 10
Mean duration: 16.42
Median duration: 16.38
Min duration: 16.27
Max duration: 16.77
---------------------------------------------------------------------------
                                                   File  Call  Line #                                                                                       Source code  mean_time  median_time  std_time                                                                                     Triggered by
                           /diffusers/modeling_utils.py  True      96                                                                  /torch/serialization.py:653 load       1.73         1.72      0.04                                           return torch.load(checkpoint_file, map_location="cpu")
                           /diffusers/modeling_utils.py  True     483                                                 /diffusers/configuration_utils.py:140 from_config       1.00         0.99      0.01                                                 model = cls.from_config(config, **unused_kwargs)
                           /diffusers/modeling_utils.py  True     488                                                   /diffusers/modeling_utils.py:90 load_state_dict       1.73         1.72      0.04                                                         state_dict = load_state_dict(model_file)
                           /diffusers/pipeline_utils.py  True     270                                                                /torch/nn/modules/module.py:881 to       2.00         1.99      0.88                                                                          module.to(torch_device)
                           /diffusers/pipeline_utils.py  True     270                                                           /transformers/modeling_utils.py:1674 to       1.66         1.66      0.86                                                                          module.to(torch_device)
                           /diffusers/pipeline_utils.py  True     708                                                  /diffusers/modeling_utils.py:286 from_pretrained       3.34         3.32      0.04              loaded_sub_model = load_method(os.path.join(cached_folder, name), **loading_kwargs)
                           /diffusers/pipeline_utils.py  True     708                                              /transformers/modeling_utils.py:1704 from_pretrained       2.07         2.10      0.07              loaded_sub_model = load_method(os.path.join(cached_folder, name), **loading_kwargs)
                           /diffusers/pipeline_utils.py  True     708                                     /transformers/tokenization_utils_base.py:1593 from_pretrained       2.03         2.00      0.05              loaded_sub_model = load_method(os.path.join(cached_folder, name), **loading_kwargs)
/diffusers/pipelines/stable_diffusion/safety_checker.py  True      41                                           /transformers/models/clip/modeling_clip.py:887 __init__       2.81         2.80      0.02                                        self.vision_model = CLIPVisionModel(config.vision_config)
                                      /ftfy/__init__.py  True      13                                             # <frozen importlib._bootstrap>:1053 _handle_fromlist       1.64         1.63      0.03                                                                 from ftfy import chardata, fixes
     /root/.pyenv/versions/3.10.11/lib/python3.10/re.py  True     251                                 # /root/.pyenv/versions/3.10.11/lib/python3.10/re.py:288 _compile       1.33         1.33      0.02                                                                  return _compile(pattern, flags)
     /root/.pyenv/versions/3.10.11/lib/python3.10/re.py  True     303                         # /root/.pyenv/versions/3.10.11/lib/python3.10/sre_compile.py:783 compile       1.34         1.34      0.02                                                          p = sre_compile.compile(pattern, flags)
                                        /src/predict.py  True      38                                              /transformers/modeling_utils.py:1704 from_pretrained       5.11         5.10      0.04                                   safety_checker = StableDiffusionSafetyChecker.from_pretrained(
                                        /src/predict.py  True      43                                                  /diffusers/pipeline_utils.py:286 from_pretrained       7.61         7.60      0.10                                             self.pipe = StableDiffusionPipeline.from_pretrained(
                                        /src/predict.py  True      48                                                               /diffusers/pipeline_utils.py:254 to       3.68         3.66      0.05                                                                                     ).to("cuda")
                                      /torch/nn/init.py False     412                                                             return tensor.uniform_(-bound, bound)       2.55         2.54      0.02                                                                                             None
                            /torch/nn/modules/linear.py  True     101                                                  /torch/nn/modules/linear.py:103 reset_parameters       2.77         2.76      0.02                                                                          self.reset_parameters()
                            /torch/nn/modules/linear.py  True     107                                                            /torch/nn/init.py:366 kaiming_uniform_       2.65         2.65      0.02                                               init.kaiming_uniform_(self.weight, a=math.sqrt(5))
                            /torch/nn/modules/module.py  True     639                                                            /torch/nn/modules/module.py:637 _apply       3.67         3.65      0.05                                                                                module._apply(fn)
                            /torch/nn/modules/module.py  True     662                                                           /torch/nn/modules/module.py:981 convert       3.22         3.21      0.05                                                                        param_applied = fn(param)
                            /torch/nn/modules/module.py False     985     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)       3.17         3.15      0.05                                                                                             None
                            /torch/nn/modules/module.py  True     987                                                            /torch/nn/modules/module.py:637 _apply       3.67         3.65      0.05                                                                      return self._apply(convert)
                                /torch/serialization.py  True     789                                                                /torch/serialization.py:1071 _load       3.67         3.68      0.09                    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
                                /torch/serialization.py False    1079 storage = zip_file.get_storage_from_record(name, numel, torch.UntypedStorage).storage().untyped()       2.88         2.90      0.09                                                                                             None
                                /torch/serialization.py  True    1101                                                          /torch/serialization.py:1076 load_tensor       3.28         3.29      0.09                                   load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
                                /torch/serialization.py  True    1131                                                      /torch/serialization.py:1086 persistent_load       3.46         3.48      0.09                                                                        result = unpickler.load()
                        /transformers/modeling_utils.py  True     399                                                                  /torch/serialization.py:653 load       1.94         1.97      0.07                                           return torch.load(checkpoint_file, map_location="cpu")
                        /transformers/modeling_utils.py  True     469                                            /torch/nn/modules/module.py:1501 _load_from_state_dict       1.05         1.05      0.02                                                              module._load_from_state_dict(*args)
                        /transformers/modeling_utils.py  True     473                                                          /transformers/modeling_utils.py:448 load       1.34         1.33      0.03                                                     load(child, state_dict, prefix + name + ".")
                        /transformers/modeling_utils.py  True     475                                                          /transformers/modeling_utils.py:448 load       1.35         1.34      0.03                                             load(model_to_load, state_dict, prefix=start_prefix)
                        /transformers/modeling_utils.py  True    1682                                                                /torch/nn/modules/module.py:881 to       1.66         1.66      0.86                                                               return super().to(*args, **kwargs)
                        /transformers/modeling_utils.py  True    2230                                               /transformers/modeling_utils.py:380 load_state_dict       1.32         1.32      0.01                                              state_dict = load_state_dict(resolved_archive_file)
                        /transformers/modeling_utils.py  True    2276                               /diffusers/pipelines/stable_diffusion/safety_checker.py:38 __init__       2.82         2.81      0.02                                                 model = cls(config, *model_args, **model_kwargs)
                        /transformers/modeling_utils.py  True    2379                                       /transformers/modeling_utils.py:2420 _load_pretrained_model       2.41         2.43      0.07                                                                  ) = cls._load_pretrained_model(
                        /transformers/modeling_utils.py  True    2602                                   /transformers/modeling_utils.py:422 _load_state_dict_into_model       1.36         1.35      0.03                error_msgs = _load_state_dict_into_model(model_to_load, state_dict, start_prefix)
             /transformers/models/clip/modeling_clip.py  True     354                                           /transformers/models/clip/modeling_clip.py:234 __init__       1.12         1.12      0.01                                                           self.self_attn = CLIPAttention(config)
             /transformers/models/clip/modeling_clip.py  True     356                                           /transformers/models/clip/modeling_clip.py:336 __init__       1.79         1.79      0.01                                                                       self.mlp = CLIPMLP(config)
             /transformers/models/clip/modeling_clip.py  True     581                                           /transformers/models/clip/modeling_clip.py:351 __init__       3.03         3.03      0.02 self.layers = nn.ModuleList([CLIPEncoderLayer(config) for _ in range(config.num_hidden_layers)])
             /transformers/models/clip/modeling_clip.py  True     581                                         /transformers/models/clip/modeling_clip.py:581 <listcomp>       3.03         3.03      0.02 self.layers = nn.ModuleList([CLIPEncoderLayer(config) for _ in range(config.num_hidden_layers)])
             /transformers/models/clip/modeling_clip.py  True     829                                           /transformers/models/clip/modeling_clip.py:578 __init__       2.79         2.78      0.02                                                               self.encoder = CLIPEncoder(config)
             /transformers/models/clip/modeling_clip.py  True     889                                           /transformers/models/clip/modeling_clip.py:822 __init__       2.81         2.80      0.02                                                self.vision_model = CLIPVisionTransformer(config)
         /transformers/models/clip/tokenization_clip.py  True     314                                               # <frozen importlib._bootstrap>:1022 _find_and_load       1.67         1.67      0.03                                                                                      import ftfy
               /transformers/tokenization_utils_base.py  True    1801                                    /transformers/tokenization_utils_base.py:1813 _from_pretrained       2.02         2.00      0.05                                                                     return cls._from_pretrained(
               /transformers/tokenization_utils_base.py  True    1956                                       /transformers/models/clip/tokenization_clip.py:289 __init__       2.02         1.99      0.05                                                     tokenizer = cls(*init_inputs, **init_kwargs)
                          <frozen importlib._bootstrap>  True     241                                               # <frozen importlib._bootstrap>:1022 _find_and_load       1.64         1.63      0.03                                                                                                 
                          <frozen importlib._bootstrap>  True     241                                                                      /ftfy/__init__.py:1 <module>       1.67         1.67      0.03                                                                                                 
                          <frozen importlib._bootstrap>  True     688                                          # <frozen importlib._bootstrap_external>:877 exec_module       1.78         1.78      0.03                                                                                                 
                          <frozen importlib._bootstrap>  True    1006                                                # <frozen importlib._bootstrap>:664 _load_unlocked       1.78         1.78      0.03                                                                                                 
                          <frozen importlib._bootstrap>  True    1027                                       # <frozen importlib._bootstrap>:987 _find_and_load_unlocked       1.79         1.78      0.03                                                                                                 
                          <frozen importlib._bootstrap>  True    1078                                     # <frozen importlib._bootstrap>:233 _call_with_frames_removed       1.64         1.63      0.03                                                                                                 
                 <frozen importlib._bootstrap_external>  True     883                                     # <frozen importlib._bootstrap>:233 _call_with_frames_removed       1.78         1.77      0.03                                                                                                 