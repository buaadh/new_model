{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.10.11/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from cog import BasePredictor, Input, Path\n",
    "from diffusers import (\n",
    "    StableDiffusionPipeline,\n",
    "    PNDMScheduler,\n",
    "    LMSDiscreteScheduler,\n",
    "    DDIMScheduler,\n",
    "    EulerDiscreteScheduler,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    "    DPMSolverMultistepScheduler,\n",
    ")\n",
    "from diffusers.pipelines.stable_diffusion.safety_checker import (\n",
    "    StableDiffusionSafetyChecker,\n",
    ")\n",
    "\n",
    "import time\n",
    "import pprofile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.pipeline_utils import DiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"stabilityai/stable-diffusion-2-1\"\n",
    "MODEL_CACHE = \"diffusers-cache\"\n",
    "SAFETY_MODEL_ID = \"CompVis/stable-diffusion-safety-checker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Serialize safety checker\n",
    "import torch\n",
    "from tensorizer import TensorSerializer\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "safety_checker = StableDiffusionSafetyChecker.from_pretrained(\n",
    "    SAFETY_MODEL_ID,\n",
    "    cache_dir=MODEL_CACHE,\n",
    "    local_files_only=True,\n",
    ").to('cuda')\n",
    "\n",
    "path = 'diffusers-cache/safety_checker.tensors'\n",
    "serializer = TensorSerializer(path)\n",
    "serializer.write_module(safety_checker)\n",
    "serializer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CompVis/stable-diffusion-safety-checker'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAFETY_MODEL_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load tensorized safety checker\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from tensorizer import TensorDeserializer\n",
    "from tensorizer.utils import no_init_or_tensor, convert_bytes, get_mem_usage\n",
    "\n",
    "with no_init_or_tensor():\n",
    "    model = StableDiffusionSafetyChecker.from_pretrained(\n",
    "        # SAFETY_MODEL_ID,\n",
    "        # cache_dir=MODEL_CACHE,\n",
    "        # local_files_only=True,\n",
    "    )\n",
    "\n",
    "deserializer = TensorDeserializer(path, plaid_mode=True)\n",
    "deserializer.load_into_module(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize safety checker\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    safety_checker=safety_checker,\n",
    "    cache_dir=MODEL_CACHE,\n",
    "    local_files_only=True,\n",
    ").to(\"cuda\")\n",
    "\n",
    "tensorized_weights_base_path = \"diffusers-cache/\"\n",
    "component_map = {}\n",
    "for k, component in pipe.components.items():\n",
    "    if isinstance(component, torch.nn.Module):\n",
    "        path = os.path.join(tensorized_weights_base_path, f\"{k}.tensors\")\n",
    "        serializer = TensorSerializer(path)\n",
    "        serializer.write_module(component)\n",
    "        serializer.close()\n",
    "        component_map[k] = path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import (\n",
    "    AutoencoderKL, \n",
    "    CLIPTextModel,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae <class 'diffusers.models.vae.AutoencoderKL'>\n",
      "text_encoder <class 'transformers.models.clip.modeling_clip.CLIPTextModel'>\n",
      "tokenizer <class 'transformers.models.clip.tokenization_clip.CLIPTokenizer'>\n",
      "unet <class 'diffusers.models.unet_2d_condition.UNet2DConditionModel'>\n",
      "scheduler <class 'diffusers.schedulers.scheduling_ddim.DDIMScheduler'>\n",
      "safety_checker <class 'diffusers.pipelines.stable_diffusion.safety_checker.StableDiffusionSafetyChecker'>\n",
      "feature_extractor <class 'transformers.models.clip.image_processing_clip.CLIPImageProcessor'>\n"
     ]
    }
   ],
   "source": [
    "component_map = {}\n",
    "for k,v in pipe.components.items():\n",
    "    print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vae...\n",
      "Loading text_encoder...\n",
      "Loading unet...\n",
      "Loading safety_checker...\n",
      "Loading tokenizer...\n",
      "Loading feature_extractor...\n"
     ]
    }
   ],
   "source": [
    "# Load StableDiffusion Components\n",
    "\n",
    "# from diffusers import (\n",
    "#     AutoencoderKL,\n",
    "#     UNet2DConditionModel,\n",
    "# )\n",
    "\n",
    "# from diffusers.pipelines.stable_diffusion.safety_checker import (\n",
    "#     StableDiffusionSafetyChecker,\n",
    "# )\n",
    "\n",
    "# from transformers import (\n",
    "#     CLIPTextModel,\n",
    "#     CLIPTokenizer,\n",
    "#     CLIPImageProcessor\n",
    "# )\n",
    "\n",
    "import diffusers\n",
    "import transformers\n",
    "\n",
    "component_map = {\n",
    "    'vae': {\n",
    "            'tensorized_weights': 'diffusers-cache/vae.tensors',\n",
    "            'path': 'diffusers-cache/models--stabilityai--stable-diffusion-2-1/snapshots/845609e6cf0a060d8cd837297e5c169df5bff72c/vae',\n",
    "            'cls': diffusers.models.vae.AutoencoderKL\n",
    "        },\n",
    "    'text_encoder': {\n",
    "            'tensorized_weights': 'diffusers-cache/text_encoder.tensors',\n",
    "            'path': 'diffusers-cache/models--stabilityai--stable-diffusion-2-1/snapshots/845609e6cf0a060d8cd837297e5c169df5bff72c/text_encoder',\n",
    "            'cls': transformers.models.clip.modeling_clip.CLIPTextModel,\n",
    "        },\n",
    "    'unet': {\n",
    "            'tensorized_weights': 'diffusers-cache/unet.tensors',  \n",
    "            'path': 'diffusers-cache/models--stabilityai--stable-diffusion-2-1/snapshots/845609e6cf0a060d8cd837297e5c169df5bff72c/unet',\n",
    "            'cls': diffusers.models.unet_2d_condition.UNet2DConditionModel\n",
    "        },\n",
    "    'safety_checker': {\n",
    "            'tensorized_weights': 'diffusers-cache/safety_checker.tensors',\n",
    "            'path': 'diffusers-cache/models--CompVis--stable-diffusion-safety-checker/snapshots/cb41f3a270d63d454d385fc2e4f571c487c253c5',\n",
    "            'cls': diffusers.pipelines.stable_diffusion.safety_checker.StableDiffusionSafetyChecker\n",
    "        },\n",
    "    'tokenizer': {\n",
    "            'path': 'diffusers-cache/models--stabilityai--stable-diffusion-2-1/snapshots/845609e6cf0a060d8cd837297e5c169df5bff72c/tokenizer',\n",
    "            'cls': transformers.models.clip.tokenization_clip.CLIPTokenizer,\n",
    "        },\n",
    "    'feature_extractor': {\n",
    "            'path': 'diffusers-cache/models--stabilityai--stable-diffusion-2-1/snapshots/845609e6cf0a060d8cd837297e5c169df5bff72c/feature_extractor',\n",
    "            'cls': transformers.models.clip.image_processing_clip.CLIPImageProcessor,\n",
    "        },\n",
    "}\n",
    "\n",
    "components = {}\n",
    "for k in component_map.keys():\n",
    "    print(f'Loading {k}...')\n",
    "    cls = component_map[k].get('cls')\n",
    "    path = component_map[k].get('path')\n",
    "    tensorized_weights = component_map[k].get('tensorized_weights', None)\n",
    "\n",
    "    if tensorized_weights:\n",
    "        with no_init_or_tensor():\n",
    "            model = cls.from_pretrained(path)\n",
    "        \n",
    "        deserializer = TensorDeserializer(tensorized_weights, plaid_mode=True)\n",
    "        deserializer.load_into_module(model)\n",
    "\n",
    "        components[k] = model\n",
    "    \n",
    "    else:\n",
    "        model = cls.from_pretrained(path)\n",
    "        components[k] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae <class 'diffusers.models.vae.AutoencoderKL'>\n",
      "text_encoder <class 'transformers.models.clip.modeling_clip.CLIPTextModel'>\n",
      "tokenizer <class 'transformers.models.clip.tokenization_clip.CLIPTokenizer'>\n",
      "unet <class 'diffusers.models.unet_2d_condition.UNet2DConditionModel'>\n",
      "scheduler <class 'diffusers.schedulers.scheduling_ddim.DDIMScheduler'>\n",
      "safety_checker <class 'diffusers.pipelines.stable_diffusion.safety_checker.StableDiffusionSafetyChecker'>\n",
      "feature_extractor <class 'transformers.models.clip.image_processing_clip.CLIPImageProcessor'>\n"
     ]
    }
   ],
   "source": [
    "component_map = {}\n",
    "for k,v in pipe.components.items():\n",
    "    print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with no_init_or_tensor():\n",
    "    model = StableDiffusionSafetyChecker.from_pretrained(\n",
    "        SAFETY_MODEL_ID,\n",
    "        cache_dir=MODEL_CACHE,\n",
    "        local_files_only=True,\n",
    "    )\n",
    "\n",
    "deserializer = TensorDeserializer(path, plaid_mode=True)\n",
    "deserializer.load_into_module(model)\n",
    "\n",
    "\n",
    "component.from_json_file('diffusers-cache/models--stabilityai--stable-diffusion-2-1/snapshots/845609e6cf0a060d8cd837297e5c169df5bff72c/feature_extractor/preprocessor_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vae': {'path': 'diffusers-cache/vae.tensors',\n",
       "  'cls': diffusers.models.vae.AutoencoderKL},\n",
       " 'text_encoder': {'path': 'diffusers-cache/text_encoder.tensors',\n",
       "  'cls': transformers.models.clip.modeling_clip.CLIPTextModel},\n",
       " 'unet': {'path': 'diffusers-cache/unet.tensors',\n",
       "  'cls': diffusers.models.unet_2d_condition.UNet2DConditionModel},\n",
       " 'safety_checker': {'path': 'diffusers-cache/safety_checker.tensors',\n",
       "  'cls': diffusers.pipelines.stable_diffusion.safety_checker.StableDiffusionSafetyChecker}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorized_weights_base_path = \"diffusers-cache/\"\n",
    "component_map = {}\n",
    "for k, component in pipe.components.items():\n",
    "    if isinstance(component, torch.nn.Module):\n",
    "        path = os.path.join(tensorized_weights_base_path, f\"{k}.tensors\")\n",
    "        # serializer = TensorSerializer(path)\n",
    "        # serializer.write_module(component)\n",
    "        # serializer.close()\n",
    "        component_map[k] = {'path': path, 'cls': type(component)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vae': {'path': 'diffusers-cache/vae.tensors',\n",
       "  'cls': diffusers.models.vae.AutoencoderKL},\n",
       " 'text_encoder': {'path': 'diffusers-cache/text_encoder.tensors',\n",
       "  'cls': transformers.models.clip.modeling_clip.CLIPTextModel},\n",
       " 'unet': {'path': 'diffusers-cache/unet.tensors',\n",
       "  'cls': diffusers.models.unet_2d_condition.UNet2DConditionModel},\n",
       " 'safety_checker': {'path': 'diffusers-cache/safety_checker.tensors',\n",
       "  'cls': diffusers.pipelines.stable_diffusion.safety_checker.StableDiffusionSafetyChecker}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "component_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vae', 'text_encoder', 'tokenizer', 'unet', 'scheduler', 'safety_checker', 'feature_extractor'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.components.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(pipe.components, torch.nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae <class 'diffusers.models.vae.AutoencoderKL'>\n",
      "text_encoder <class 'transformers.models.clip.modeling_clip.CLIPTextModel'>\n",
      "tokenizer <class 'transformers.models.clip.tokenization_clip.CLIPTokenizer'>\n",
      "unet <class 'diffusers.models.unet_2d_condition.UNet2DConditionModel'>\n",
      "scheduler <class 'diffusers.schedulers.scheduling_ddim.DDIMScheduler'>\n",
      "safety_checker <class 'diffusers.pipelines.stable_diffusion.safety_checker.StableDiffusionSafetyChecker'>\n",
      "feature_extractor <class 'transformers.models.clip.image_processing_clip.CLIPImageProcessor'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vae', 'text_encoder', 'tokenizer', 'unet', 'scheduler', 'safety_checker', 'feature_extractor'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.components.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
